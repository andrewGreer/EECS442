{"cells":[{"cell_type":"markdown","metadata":{"id":"ix5dQS2rUMlu"},"source":["## EECS 442 PS3: Learning\n","\n","__Please provide the following information__\n","(e.g. Andrew Owens, ahowens):\n","\n","[Your first name] [Your last name], [Your UMich uniqname]\n","\n","__Important__: after you download the .ipynb file, please name it as __\\<your_uniquename\\>_\\<your_umid\\>.ipynb__ before you submit it to canvas. Example: adam_01101100.ipynb.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"W_Cst4k4tuBc"},"source":["## Initialization\n","\n","Run the following code to import the modules you'll need. After your finish the assignment, remember to run all cells and save the note book to your local machine as a .ipynb file for Canvas submission."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2BIzvYlCysit"},"outputs":[],"source":["import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import platform\n","import random\n","from random import randrange\n","from skimage.color import rgb2gray\n","from skimage.feature import hog\n","import time\n","import torch\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import torchvision.transforms as transforms\n","import glob\n","\n","random.seed(0)\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"mOkFjkLKSjjI"},"source":["# 1. Setup dataset\n","\n","In this section we will download the dataset, unzip it and setup the paths to load images from.\n","\n","This dataset is a very tiny subset of the popular [ImageNet](https://www.image-net.org/) dataset. This dataset is used for image classification.\n","\n","This tiny dataset has **10 classes** : [ fish, English-springer, cassette-player, chain-saw, church, French-horn, garbage-truck, gas-pump, golf-ball, parachute ]  \n","\n","It contains a total of **9538 training images** and **3856 test images**.\n","\n","The dataset is in the format:\n","```\n","dataset\n","  ---train\n","     ---class1\n","     ---class2\n","             .\n","             .\n","  ---test\n","     ---class1\n","     ---class2\n","             .\n","             .\n","```\n","The data has been cleaned and we have provided dataloading functions below so you can directly use the dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSHEaEFidInB"},"outputs":[],"source":["!wget \"https://www.eecs.umich.edu/courses/eecs442-ahowens/fa22/data/imagenette.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVgrvuYidUHk"},"outputs":[],"source":["!unzip -qq \"/content/imagenette.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2EzFqpmhcDh"},"outputs":[],"source":["train_data_path = '/content/imagenette/train'\n","test_data_path = '/content/imagenette/test'\n","\n","train_image_paths = [] #to store image paths in list\n","test_image_paths = []\n","classes = [] #to store class values\n","\n","# get all the paths from train_data_path and append image paths and class to to respective lists\n","\n","for data_path in glob.glob(train_data_path + '/*'):\n","    classes.append(data_path.split('/')[-1])\n","    train_image_paths.append(glob.glob(data_path + '/*'))\n","\n","for data_path in glob.glob(test_data_path + '/*'):\n","    test_image_paths.append(glob.glob(data_path + '/*'))\n","\n","train_image_paths = list(sum(train_image_paths,[]))\n","random.shuffle(train_image_paths)\n","\n","test_image_paths = list(sum(test_image_paths,[]))\n","\n","# create a dictionary holding corresponding class names(text) for labels(index)\n","# this will help when visualizing to print class names\n","idx_to_class = {i:j for i, j in enumerate(classes)}\n","class_to_idx = {value:key for key,value in idx_to_class.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owLaijCLfxBM"},"outputs":[],"source":["# This class derives from Dataset class in PyTorch\n","# Transforms are common image transformations (preprocessing steps) available in\n","#the torchvision.transforms module. They can be chained together using Compose.\n","class ImageDataset(Dataset):\n","    def __init__(self, img_paths, img_shape, is_tensor = False):\n","\n","        self.img_paths = img_paths\n","        self.img_shape = img_shape\n","\n","        if is_tensor:\n","            self.img_transform = transforms.Compose(\n","                [\n","                    transforms.Resize((img_shape,img_shape)),\n","                    transforms.ToTensor()\n","                ]\n","            )\n","        else:\n","            self.img_transform = transforms.Compose(\n","                [\n","                    transforms.Resize((img_shape,img_shape))\n","                ]\n","            )\n","\n","    def __getitem__(self, index):\n","        # this function loads a single image from its path and returns the image\n","        # as an array along with its label\n","        #The __get__item function is called internally by the DataLoader function from torchvision.transforms.\n","\n","        \"\"\"\n","        Returns an example at given index.\n","\n","        Args:\n","            index(int): The index of the example to retrieve\n","\n","        Returns:\n","            img: The image at the given index\n","            label: The label associated with the given image\n","        \"\"\"\n","        img_filepath = self.img_paths[index]\n","        img = Image.open(img_filepath)\n","        img = self.img_transform(img)\n","        img = np.asarray(img,dtype=np.float64)\n","        label = img_filepath.split('/')[-2]\n","        label = class_to_idx[label]\n","        return img, label\n","\n","    def __len__(self):\n","\n","        \"\"\"\n","        Returns the size of the dataset or number of examples in the dataset\n","        \"\"\"\n","\n","        return len(self.img_paths)\n"]},{"cell_type":"markdown","metadata":{"id":"n7IeaDKNWDdB"},"source":["## Debug Flag\n","Set the debug flag to true when testing.\n","Setting the debug flag to true will let the dataloader use only 20% of the training dataset, which makes everything run faster. This will make testing the code easier.\n","\n","Once you finish the coding part please make sure to change the flag to False and rerun all the cells. This will make the colab ready for submission."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cw9do0BWdKc"},"outputs":[],"source":["DEBUG = False"]},{"cell_type":"markdown","metadata":{"id":"_HfxL7YJnVoI"},"source":["### OPTIONAL\n","\n","You can also text all you implementations with a higher image size by setting the image size variable below.\n","\n","**NOTE**: This cell needs to run once atleast"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucZpNWQZnhSe"},"outputs":[],"source":["img_size = 32\n","\n","# data_loader with load images as size 32x32\n","# You can try with img_size = 64 to check if it improves the accuracy"]},{"cell_type":"markdown","metadata":{"id":"ScZ7irrx5gjb"},"source":[" Helper functions for gradient checking which will be used later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcB9HJn8SL_o"},"outputs":[],"source":["def grad_check_sparse(f, x, analytic_grad, num_checks=10, h=1e-5):\n","  \"\"\"\n","  sample a few random elements and only return numerical\n","  in this dimensions.\n","  \"\"\"\n","\n","  for i in range(num_checks):\n","    ix = tuple([randrange(m) for m in x.shape])\n","\n","    oldval = x[ix]\n","    x[ix] = oldval + h # increment by h\n","    fxph = f(x) # evaluate f(x + h)\n","    x[ix] = oldval - h # increment by h\n","    fxmh = f(x) # evaluate f(x - h)\n","    x[ix] = oldval # reset\n","\n","    grad_numerical = (fxph - fxmh) / (2 * h)\n","    grad_analytic = analytic_grad[ix]\n","    rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n","    print('numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error))"]},{"cell_type":"markdown","metadata":{"id":"eta6H0d-1_u6"},"source":["## Load and visualize Tiny ImageNet dataset\n"]},{"cell_type":"markdown","metadata":{"id":"-IJChljsOG5w"},"source":["### Visualize some examples from the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qaDrAExemWDc"},"outputs":[],"source":["train_dataset = ImageDataset(train_image_paths,img_shape=150,is_tensor=False)\n","\n","def visualize_data(train_dataset, num_samples):\n","    figure, ax = plt.subplots(nrows=num_samples//5, ncols=5, figsize=(15, 8))\n","    for i in range(5*(num_samples//5)):\n","        image, lab = train_dataset[i]\n","        ax.ravel()[i].imshow(np.uint8(image))\n","        ax.ravel()[i].set_axis_off()\n","        ax.ravel()[i].set_title(idx_to_class[lab])\n","    plt.tight_layout(pad=1)\n","    plt.show()\n","\n","visualize_data(train_dataset, 30 )"]},{"cell_type":"markdown","metadata":{"id":"PZ0KL4w6bjEj"},"source":["### Load the entire dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAR31Ubu6gwD"},"outputs":[],"source":["train_dataset = ImageDataset(train_image_paths, img_shape=img_size, is_tensor=False)\n","test_dataset = ImageDataset(test_image_paths, img_shape=img_size, is_tensor=False)\n","\n","train_batch_size = train_dataset.__len__()\n","test_batch_size = test_dataset.__len__()\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset, batch_size=test_batch_size, shuffle=True\n",")\n","\n","iterator = iter(train_loader)\n","for batch_train in train_loader:\n","    X_train, y_train = batch_train\n","\n","iterator = iter(test_loader)\n","for batch_test in test_loader:\n","    X_test, y_test = batch_test\n","\n","X_train = X_train.numpy()\n","y_train = y_train.numpy()\n","X_test = X_test.numpy()\n","y_test = y_test.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSJFucK5YG26"},"outputs":[],"source":["# Take a smaller subset of the training set for efficient execution of kNN\n","# We also create a small validation set\n","\n","if DEBUG:\n","  knn_num_train = 1900\n","  knn_num_val = 100\n","  knn_num_test =  700\n","else:\n","  knn_num_train = 9000\n","  knn_num_val = 538\n","  knn_num_test =  3856\n","\n","# Create a dictionary of data for easy access when testing\n","knn_data_dict = {}\n","\n","knn_data_dict['X_train'] = X_train[:knn_num_train].reshape(knn_num_train, -1)\n","knn_data_dict['y_train'] = y_train[:knn_num_train]\n","\n","knn_data_dict['X_val'] = X_train[knn_num_train:knn_num_train+knn_num_val].reshape(knn_num_val, -1)\n","knn_data_dict['y_val'] = y_train[knn_num_train:knn_num_train+knn_num_val]\n","\n","knn_data_dict['X_test'] = X_test[:knn_num_test].reshape(knn_num_test, -1)\n","knn_data_dict['y_test'] = y_test[:knn_num_test]\n","\n","\n","print('Train data shape: ', knn_data_dict['X_train'].shape)\n","print('Train labels shape: ', knn_data_dict['y_train'].shape)\n","print('Validation data shape: ', knn_data_dict['X_val'].shape)\n","print('Validation labels shape: ', knn_data_dict['y_val'].shape)\n","print('Test data shape: ', knn_data_dict['X_test'].shape)\n","print('Test labels shape: ', knn_data_dict['y_test'].shape)\n"]},{"cell_type":"markdown","metadata":{"id":"8THuRKUIWDjO"},"source":["## **Problem 3.1**"]},{"cell_type":"markdown","metadata":{"id":"qp8Gf7Huay6h"},"source":["### (a) Define the KNearestNeighbor class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiGqWFqgXZGV"},"outputs":[],"source":["from collections import Counter\n","class KNearestNeighbor(object):\n","  \"\"\" a kNN classifier with L2 distance \"\"\"\n","\n","  def __init__(self):\n","    pass\n","\n","  def train(self, X, y):\n","    \"\"\"\n","    Train the classifier. For k-nearest neighbors this is just\n","    memorizing the training data.\n","    Inputs:\n","    - X: A numpy array of shape (num_train, D) containing the training data\n","      consisting of num_train samples each of dimension D.\n","    - y: A numpy array of shape (N,) containing the training labels, where\n","         y[i] is the label for X[i].\n","    \"\"\"\n","    self.X_train = X\n","    self.y_train = y\n","\n","  def predict(self, X, k=1, num_loops=0):\n","    \"\"\"\n","    Predict labels for test data using this classifier.\n","    Inputs:\n","    - X: A numpy array of shape (num_test, D) containing test data consisting\n","         of num_test samples each of dimension D.\n","    - k: The number of nearest neighbors that vote for the predicted labels.\n","    - num_loops: Determines which implementation to use to compute distances\n","      between training points and testing points.\n","    Returns:\n","    - y: A numpy array of shape (num_test,) containing predicted labels for the\n","      test data, where y[i] is the predicted label for the test point X[i].\n","    \"\"\"\n","    if num_loops == 0:\n","      dists = self.compute_distances_no_loops(X)\n","    elif num_loops == 1:\n","      dists = self.compute_distances_one_loop(X)\n","    elif num_loops == 2:\n","      dists = self.compute_distances_two_loops(X)\n","    else:\n","      raise ValueError('Invalid value %d for num_loops' % num_loops)\n","\n","    return self.predict_labels(dists, k=k)\n","\n","  def compute_distances_two_loops(self, X):\n","    \"\"\"\n","    Compute the l2 distance between each test point in X and each training point\n","    in self.X_train using a nested loop over both the training data and the\n","    test data.\n","    Inputs:\n","    - X: A numpy array of shape (num_test, D) containing test data.\n","    Returns:\n","    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n","      is the Euclidean distance between the ith test point and the jth training\n","      point.\n","    \"\"\"\n","    num_test = X.shape[0]\n","    num_train = self.X_train.shape[0]\n","    dists = np.zeros((num_test, num_train))\n","    for i in range(num_test):\n","      for j in range(num_train):\n","\n","        # ===== your code here! =====\n","\n","        # TODO:\n","        # Compute the l2 distance between the ith test image and the jth\n","        # training image, and store the result in dists[i, j].\n","\n","\n","        # ==== end of code ====\n","\n","    return dists\n","\n","  def compute_distances_one_loop(self, X):\n","    \"\"\"\n","    Compute the l2 distance between each test point in X and each training point\n","    in self.X_train using a single loop over the test data.\n","    Input / Output: Same as compute_distances_two_loops\n","    \"\"\"\n","    num_test = X.shape[0]\n","    num_train = self.X_train.shape[0]\n","    dists = np.zeros((num_test, num_train))\n","    for i in range(num_test):\n","\n","      # ===== your code here! =====\n","\n","      # TODO:\n","      # Compute the l2 distance between the ith test point and all training\n","      # points, and store the result in dists[i, :].\n","\n","\n","      # ==== end of code ====\n","\n","    return dists\n","\n","  def compute_distances_no_loops(self, X):\n","    \"\"\"\n","    Compute the l2 distance between each test point in X and each training point\n","    in self.X_train using no explicit loops.\n","    Input / Output: Same as compute_distances_two_loops\n","    \"\"\"\n","    num_test = X.shape[0]\n","    num_train = self.X_train.shape[0]\n","    dists = np.zeros((num_test, num_train))\n","\n","    # ===== your code here! =====\n","\n","    # TODO:\n","    # Compute the l2 distance between all test points and all training\n","    # points without using any explicit loops, and store the result in\n","    # dists.\n","    #\n","    # You should implement this function using only basic array operations;\n","    # in particular you should not use functions from scipy.\n","    #\n","    # HINT: ||x - y||^2 = ||x||^2 + ||y||^2 - 2x y^T\n","\n","\n","    # ==== end of code ====\n","\n","    return dists\n","\n","  def predict_labels(self, dists, k=1):\n","    \"\"\"\n","    Given a matrix of distances between test points and training points,\n","    predict a label for each test point.\n","    Inputs:\n","    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n","      gives the distance betwen the ith test point and the jth training point.\n","    Returns:\n","    - y: A numpy array of shape (num_test,) containing predicted labels for the\n","      test data, where y[i] is the predicted label for the test point X[i].\n","    - knn_idxs: List of arrays, containing Indexes of the k nearest neighbors\n","      for the test data. So, for num_tests, it will be a list of length\n","      num_tests with each element of the list, an array of size 'k'. This will\n","      be used for visualization purposes later.\n","    \"\"\"\n","    num_test = dists.shape[0]\n","    y_pred = np.zeros(num_test)\n","    knn_idxs = []\n","    for i in range(num_test):\n","      # A list of length k storing the labels of the k nearest neighbors to\n","      # the ith test point.\n","\n","      closest_y = []\n","\n","      # ===== your code here! =====\n","\n","      # TODO:\n","      # Use the distance matrix to find the k nearest neighbors of the ith\n","      # testing element, and use self.y_train to find the labels of these\n","      # neighbors. Store these labels in closest_y.\n","      # Also, don't forget to apprpriately store indices knn_idxs list.\n","      # Hint: Look up the function numpy.argsort.\n","\n","\n","      # ==== end of code ====\n","\n","      # Now that you have found the labels of the k nearest neighbors, the code\n","      # below finds the most common label in the list closest_y of labels.\n","      # and stores this label in y_pred[i]. We break ties by choosing the\n","      # smaller label.\n","\n","      vote = Counter(closest_y)\n","      count = vote.most_common()\n","      y_pred[i] = count[0][0]\n","\n","    return y_pred, knn_idxs"]},{"cell_type":"markdown","metadata":{"id":"T82gncH_PpB4"},"source":["### (b) Check L2 distance implementation\n","Now, let's do some checks to see if you have implemented the functions correctly. We will first calculate the distances using ***compute_distance_two_loops*** function and check the accuracies for k=1 and k=3.\n","Then, we will compare the ***compute_distance_one_loop*** and ***compute_distance_no_loop*** functions with it to check their consistency with the ***compute_distance_two_loops*** function."]},{"cell_type":"markdown","metadata":{"id":"em41Ep_nOxzu"},"source":["Initialize the KNN Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2lQm_eIZ-Ti"},"outputs":[],"source":["classifier = KNearestNeighbor()\n","classifier.train(knn_data_dict['X_train'], knn_data_dict['y_train'])"]},{"cell_type":"markdown","metadata":{"id":"PHeCw3QxREQD"},"source":["Compute the distance between the training and test set.\n","This might take some time to run since we are running the two loops function which is not efficient.\n","\n","**6 to 8 mins for full dataset | 2 to 3 mins for debug dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1foVkfxbHYw"},"outputs":[],"source":["dists_two = classifier.compute_distances_two_loops(knn_data_dict['X_test'])"]},{"cell_type":"markdown","metadata":{"id":"o9rDTdtbRKvS"},"source":["Now, let's do some checks to see if you have implemented the functions correctly. We will first calculate the distances using compute_distance_two_loops function and check the accuracies for k=1 and k=3.\n","Then, we will compare the compute_distance_one_loop and compute_distance_no_loop functions with it to check their correctness.\n","\n","\n","Predict labels and check accuracy for k = 1.\n","You should expect to see approximately 28% accuracy for full dataset.  \n","**(Accuracy below 24% on full dataset (Debug = False) will not be given full grades)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIQYEVNpby1C"},"outputs":[],"source":["y_test_pred, k_idxs  = classifier.predict_labels(dists_two, k=1)\n","# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))"]},{"cell_type":"markdown","metadata":{"id":"q5uTqs93RVkL"},"source":["Let's predict the labels and calculate accuracy for k = 3.\n","You should expect to see a slightly better performance than with k=1. Around 30% accuracy (Not counted for grading)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOmk1rJEdfgg"},"outputs":[],"source":["y_test_pred, k_idxs = classifier.predict_labels(dists_two, k=3)\n","# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))"]},{"cell_type":"markdown","metadata":{"id":"chBnymxWfeVp"},"source":["Now lets check the one loop implementation. This should also take some time to run.  \n","**4 to 6 mins for full dataset | 1 to 2 mins for debug dataset**\n","\n","**Note:** This function can possibly take a little more time that two loop implementaion because of some quirks in python, numpy and cpu processing. It is fine as long as the final output shows no difference below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-a5UQUyVFqt"},"outputs":[],"source":["# Implement the function compute_distances_one_loop in KNearestNeighbor class\n","# and run the code below:\n","dists_one = classifier.compute_distances_one_loop(knn_data_dict['X_test'])\n","\n","# To ensure that our vectorized implementation is correct, we make sure that it\n","# agrees with the naive implementation. There are many ways to decide whether\n","# two matrices are similar; one of the simplest is the Frobenius norm. In case\n","# you haven't seen it before, the Frobenius norm of two matrices is the square\n","# root of the squared sum of differences of all elements; in other words, reshape\n","# the matrices into vectors and compute the Euclidean distance between them.\n","\n","difference = np.linalg.norm(dists_two - dists_one, ord='fro')\n","print('Difference was: %f' % (difference, ))\n","if difference < 0.001:\n","    print('Good! The distance matrices are the same')\n","else:\n","    print('Uh-oh! The distance matrices are different')"]},{"cell_type":"markdown","metadata":{"id":"4S2XdYq_ftrB"},"source":["Now lets check the vectorized implementation. This should take less than 30 secs to run for full dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqDyi4LDVmmu"},"outputs":[],"source":["# Now implement the fully vectorized version inside compute_distances_no_loops\n","# and run the code\n","dists_no = classifier.compute_distances_no_loops(knn_data_dict['X_test'])\n","\n","# check that the dist ance matrix agrees with the one we computed before:\n","difference = np.linalg.norm(dists_two - dists_no, ord='fro')\n","print('Difference was: %f' % (difference, ))\n","if difference < 0.001:\n","    print('Good! The distance matrices are the same')\n","else:\n","    print('Uh-oh! The distance matrices are different')"]},{"cell_type":"markdown","metadata":{"id":"gQLoOPEiLEuU"},"source":["Let's compare how fast the implementations are\n","You should see significantly faster performance with the fully vectorized implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCNADI70VuCK"},"outputs":[],"source":["def time_function(f, *args):\n","    \"\"\"\n","    Call a function f with args and return the time (in seconds) that it took to execute.\n","    \"\"\"\n","    import time\n","    tic = time.time()\n","    f(*args)\n","    toc = time.time()\n","    return toc - tic\n","\n","two_loop_time = time_function(classifier.compute_distances_two_loops, knn_data_dict['X_test'])\n","print('Two loop version took %f seconds' % two_loop_time)\n","\n","one_loop_time = time_function(classifier.compute_distances_one_loop, knn_data_dict['X_test'])\n","print('One loop version took %f seconds' % one_loop_time)\n","\n","no_loop_time = time_function(classifier.compute_distances_no_loops, knn_data_dict['X_test'])\n","print('No loop version took %f seconds' % no_loop_time)\n","\n","# you should see significantly faster performance with the fully vectorized implementation"]},{"cell_type":"markdown","metadata":{"id":"CixZ0HOGihXr"},"source":["### (c) Use the validation set for tuning the value of 'K'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_dYU3vH3Wlj"},"outputs":[],"source":["k_choices = [1, 3, 5, 6, 7, 8, 9, 10, 12, 15, 20, 50, 100]\n","k_accuracies = np.zeros((len(k_choices), ))\n","classifier = KNearestNeighbor()\n","max_accuracy = 0\n","max_k = 0\n","\n","classifier.train(knn_data_dict['X_train'], knn_data_dict['y_train'])\n","dists = classifier.compute_distances_no_loops(knn_data_dict['X_val'])\n","for ik, k in enumerate(k_choices):\n","\n","  # ===== your code here! =====\n","\n","  # TODO:\n","  # Find the accuracies for all the k values given in k_choices. You need to\n","  # use the validation set from the dictionary knn_data_dict already defined\n","  # for prediction and find its k nearest neighbors in the training set.\n","  # Note: Access the dataset using the knn_data_dict dictinoary defined earlier.\n","\n","  # HINT: See how we had used the KNearestNeighbor() class\n","  # functions for k=1 and k=5 in the above cells.\n","\n","\n","  # ==== end of code ====\n","\n","  if(k_accuracies[ik] > max_accuracy):\n","    max_accuracy = k_accuracies[ik]\n","    max_k = k\n","  print(\"k = %d, accuracy = %f\" %(k, k_accuracies[ik]))\n","\n","print(\"Maximum validation accuracy obtained is: %f for k = %d\" %(max_accuracy,max_k))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhM_QVTCD-Su"},"outputs":[],"source":["plt.plot(k_choices, 100*k_accuracies, 'o-')\n","plt.xlabel('K Values')\n","plt.ylabel('Validation Accuracies')"]},{"cell_type":"markdown","metadata":{"id":"EmvbxPgGuTQA"},"source":["### **TODO**:\n","Report the best accuracy and the corresponding k value in this cell below:\n"]},{"cell_type":"markdown","metadata":{"id":"5I82ZUK0HUaj"},"source":["Use the best k value you found from the validation set to evaluate you final accuracy on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NsZsz9mHTbC"},"outputs":[],"source":["# Set the value of best_k to be equal to the 'k' which gave the best accuracy\n","# for the validation set.\n","\n","best_k = max_k\n","classifier = KNearestNeighbor()\n","classifier.train(knn_data_dict['X_train'], knn_data_dict['y_train'])\n","dists = classifier.compute_distances_no_loops(knn_data_dict['X_test'])\n","y_test_pred, k_idxs  = classifier.predict_labels(dists, k=best_k)\n","# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))\n"]},{"cell_type":"markdown","metadata":{"id":"3VfFabTwRnxX"},"source":["### Visualize KNN results"]},{"cell_type":"markdown","metadata":{"id":"ELiPYRHkRvzy"},"source":["Let's visualize the K nearest images for some randomly selected examples from the test set using the k_idxs list you returned in predict_labels.  \n","\n","Here the leftmost column is the input image from the test set and rest of the\n","columns are the K nearest neighbors from the training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zoeIUHXfiXy7"},"outputs":[],"source":["def visualize_knn(num_examples, K):\n","\n","  idxs = np.random.choice(knn_num_test, num_examples,replace=False)\n","  vis_im = knn_data_dict['X_test'][idxs]\n","  _, k_idxs = classifier.predict_labels(dists, k=K)\n","  vis_labels = np.stack(k_idxs, axis=0)[idxs].astype('uint8')\n","\n","  num_images = num_examples*K + num_examples\n","\n","  plt.figure(figsize=(14,8))\n","  for i in range(num_images):\n","    plt.subplot(num_examples,K+1,i+1)\n","    if (i%(K+1) == 0):\n","      plt.imshow(vis_im[int(i/(K+1))].reshape(img_size,img_size,3).astype('uint8'), interpolation='nearest')\n","      plt.axis('off')\n","      if(i==0):\n","        plt.title('Input')\n","    else:\n","      plt.imshow(knn_data_dict['X_train'][vis_labels[int(i/(K+1)), i - (K+1)*int(i/(K+1)) - 1]].reshape(img_size,img_size,3).astype('uint8'))\n","      plt.axis('off')\n","\n","\n","# Here the leftmost column is the input image from the test set and rest of the\n","# K columns are the K nearest neighbors from the training set\n","num_examples = 5\n","K = 7\n","visualize_knn(num_examples, K)"]},{"cell_type":"markdown","metadata":{"id":"Z4ODTi-fExOS"},"source":["### *(Optional)* Does normalizing the images give better accuracy?"]},{"cell_type":"markdown","metadata":{"id":"1F34XK7n3scP"},"source":["We normalize each image here by subtracting the image by its mean and dividing by its standard deviation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7QF8kT9sDBY"},"outputs":[],"source":["X_instance_mean = np.mean(X_train, axis = (1, 2, 3))\n","X_instance_std = np.std(X_train, axis = (1, 2, 3))\n","X_test_instance_mean = np.mean(X_test, axis = (1, 2, 3))\n","X_test_instance_std = np.std(X_test, axis = (1, 2, 3))\n","X_train_instance = (X_train - X_instance_mean[:, None, None, None])/X_instance_std[:, None, None, None]\n","X_test_instance = (X_test - X_test_instance_mean[:, None, None, None])/X_test_instance_std[:, None, None, None]"]},{"cell_type":"markdown","metadata":{"id":"7j95s9Kh312K"},"source":["Store these tensors into a dictionary ``` knn_norm_data_dict ```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVBt_vNYCrC1"},"outputs":[],"source":["knn_norm_data_dict = {}\n","\n","knn_norm_data_dict['X_train'] = X_train_instance[:knn_num_train].reshape(knn_num_train, -1)\n","knn_norm_data_dict['y_train'] = y_train[:knn_num_train]\n","knn_norm_data_dict['X_val'] = X_train_instance[knn_num_train:knn_num_train+knn_num_val].reshape(knn_num_val, -1)\n","knn_norm_data_dict['y_val'] = y_train[knn_num_train:knn_num_train+knn_num_val]\n","knn_norm_data_dict['X_test'] = X_test_instance[:knn_num_test].reshape(knn_num_test, -1)\n","knn_norm_data_dict['y_test'] = y_test[:knn_num_test]\n","\n","print('Train data shape: ', knn_norm_data_dict['X_train'].shape)\n","print('Train labels shape: ', knn_norm_data_dict['y_train'].shape)\n","print('Validation data shape: ', knn_norm_data_dict['X_val'].shape)\n","print('Validation labels shape: ', knn_norm_data_dict['y_val'].shape)\n","print('Test data shape: ', knn_norm_data_dict['X_test'].shape)\n","print('Test labels shape: ', knn_norm_data_dict['y_test'].shape)"]},{"cell_type":"markdown","metadata":{"id":"QZ-5WTEg4Rl1"},"source":["We calculate the accuracies again using k = 1 and k = 3 and see that the accuracies are much better compared to those we obtained without any preprocessing on the images!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlNk0lfQC3GY"},"outputs":[],"source":["classifier = KNearestNeighbor()\n","classifier.train(knn_norm_data_dict['X_train'], knn_norm_data_dict['y_train'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfFMf50iDCKw"},"outputs":[],"source":["dists = classifier.compute_distances_no_loops(knn_norm_data_dict['X_test'])\n","y_test_pred, k_labels  = classifier.predict_labels(dists, k=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlQFv2BvDF_0"},"outputs":[],"source":["# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_norm_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCwvaqD-DLsS"},"outputs":[],"source":["y_test_pred, k_labels = classifier.predict_labels(dists, k=3)\n","# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_norm_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))"]},{"cell_type":"markdown","metadata":{"id":"PA9dWA4hgCDW"},"source":["## (d) KNN with HOG\n","The previous parts all directly used raw pixels from input images to compute distances with k-NN. In this part, we will first use the Histogram of Oriented Gradients (HOG) as features for each image. We will use these features with our kNN implementation to find the nearest neighbours. Please read the descriptions and fill in the functions below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBqaD-eCG1vU"},"outputs":[],"source":["def compute_angles(image):\n","  \"\"\"\n","    Computes the gradients in both x and y directions.\n","    Computes the magnitudes of the gradients.\n","    Computes the angles from the gradients and map to range [0, 180 deg].\n","    Inputs:\n","    - image: A numpy array of shape (32, 32) containing one grayscaled image.\n","    Returns:\n","    - magnitudes: A numpy array of shape (32, 32) where magnitudes[i, j]\n","      is the magnitude of the gradient at the (i, j) pixel in the input image.\n","    - angles: A numpy array of shape (32, 32) where angles[i, j]\n","      is the angle of the gradient at the (i, j) pixel in the input image.\n","    \"\"\"\n","\n","  # ===== your code here! =====\n","\n","  # TODO:\n","  # Compute the gradients along the rows and columns as two arrays.\n","  # Compute the magnitude as the square root of the sum of the squares of both gradients\n","  # Compute the angles as the inverse tangent of the gradients along the rows and\n","  # the gradients along the columns, and map them to the range [0, 180 deg]\n","\n","\n","  # ==== end of code ====\n","  return magnitudes, angles"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stjK-GOYHEVa"},"outputs":[],"source":["def compute_hog(angles, magnitudes, num_bins, pixels_per_cell, cells_per_block):\n","  \"\"\"\n","  Creates a Histogram of Oriented Gradients (HOG) weighted by gradient\n","  magnitudes from the orientations and magnitudes of an image\n","  Inputs:\n","  - angles: A numpy array of shape (32, 32) where angles[i, j]\n","      is the angle of the gradient at the (i, j) pixel in the input image.\n","  - magnitudes: A numpy array of shape (32, 32) where magnitudes[i, j]\n","      is the magnitude of the gradient at the (i, j) pixel in the input image.\n","  - num_bins: An int of the number of different bins in the histogram\n","    representing intervals of different orientations\n","  - pixels_per_cell: An int representing the number of rows/columns of pixels\n","    present in each cell\n","  - cells_per_block: An int representing the number of rows/columns of cells\n","    present in each block\n","  \"\"\"\n","\n","  num_cell_rows = angles.shape[0] // pixels_per_cell\n","  histogram = np.zeros((num_cell_rows, num_cell_rows, num_bins));\n","  step_size = 180 // num_bins\n","\n","  # ===== your code here! =====\n","\n","  # TODO:\n","  # Iterate through each pixel in every cell\n","  # Find the index to the bin in histogram for that pixel's orientation\n","  # Add the weighted magnitude to the corresponding bins in the histogram\n","\n","\n","  # ==== end of code ====\n","\n","  normalize_histogram(histogram, num_cell_rows, cells_per_block, epsilon=1e-5)\n","  return histogram.flatten()"]},{"cell_type":"markdown","metadata":{"id":"0FgC4NIE0kNw"},"source":["**NOTE :** Once we create a histogram based on the gradient of the image we need to normalize it. Gradients of an image are sensitive to overall lighting. If you make the image darker by dividing all pixel values by 2, the gradient magnitude will change by half, and therefore the histogram values will change by half.\n","\n","Ideally, we want our image features to be independent of lighting variations. In other words, we would like to “normalize” the histogram so they are not affected by lighting variations.\n","\n","We have provided the normalization code below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8pnHTZemNQl"},"outputs":[],"source":["def normalize_histogram(histogram, num_cell_rows, cells_per_block, epsilon=1e-5):\n","  \"\"\"\n","  Normalizes the histogram in blocks of size cells_per_block.\n","  Inputs:\n","  - histogram: A numpy array of shape (num_cell_rows, num_cell_rows, num_bins)\n","    representing the histogram of oriented gradients of the input image.\n","    It can be modified in place.\n","  - num_cell_rows: An int representing the number of rows/columns of cells\n","    in the input image.\n","  - cells_per_block: An int representing the number of rows/coluns of cells that\n","    should together be normalized in the same block.\n","  - epsilon: A float indicating the small amount added to the denominator when\n","    normalizing to avoid dividing by zero.\n","  \"\"\"\n","\n","  num_block_rows = num_cell_rows // cells_per_block\n","  # Block normalization\n","  for r in range(num_block_rows):\n","    for c in range(num_block_rows):\n","      histogram[r : r + cells_per_block, c : c + cells_per_block, :] /= np.sqrt(np.sum(np.square(histogram[r : r + cells_per_block, c : c + cells_per_block, :])) + epsilon ** 2)"]},{"cell_type":"markdown","metadata":{"id":"ltyfuLeURAd9"},"source":["After implementing your HOG functions, please run the cells below to test the results. You should expect to get an accuracy slightly higher than that with unnormalized raw pixels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX_CsGmDuj4t"},"outputs":[],"source":["def generate_histogram(image):\n","  \"\"\"\n","  Builds a Histogram of Oriented Gradients (HOG) weighted by gradient magnitudes\n","  from an input image\n","  Inputs:\n","  - image: A numpy array of shape (32, 32) containing one grayscaled image.\n","  Outputs:\n","  - histogram: A 1D numpy array of shape\n","    (num_cell_rows * num_cell_rows * num_bins, ) that shows a HOG of an image.\n","  \"\"\"\n","  # Read and reshape input image\n","  input_image = image.reshape((img_size, img_size, 3)).astype('uint8')\n","  grayscaled = rgb2gray(input_image)\n","  magnitudes, angles = compute_angles(grayscaled)\n","\n","  # 9 bin, histogram with 64 4x4 pixel cells, normalize 4 cells per block\n","  # Get histogram of 4 quadrants with 9 bins concatenated into a 8x8x9-dimensional vector\n","\n","  histogram = compute_hog(angles=angles, magnitudes=magnitudes, num_bins=9, pixels_per_cell=4, cells_per_block=4)\n","\n","  return histogram"]},{"cell_type":"markdown","metadata":{"id":"RbpG5baPmWUU"},"source":["This part will take some time to run for the full dataset. Approx 1 to 2mins."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UGNxvMjXRpe"},"outputs":[],"source":["X_train_hog = []\n","for image_index in range(X_train.shape[0]):\n","  histogram = generate_histogram(X_train[image_index])\n","  X_train_hog.append(histogram)\n","\n","X_test_hog = []\n","for image_index in range(X_test.shape[0]):\n","  histogram = generate_histogram(X_test[image_index])\n","  X_test_hog.append(histogram)"]},{"cell_type":"markdown","metadata":{"id":"sr4g8e2Zr3E1"},"source":["Store these tensors into a dictionary ``` knn_hog_data_dict ```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fdnJ8DRr_5W"},"outputs":[],"source":["knn_hog_data_dict = {}\n","\n","knn_hog_data_dict['X_train'] = np.array(X_train_hog[:knn_num_train]).reshape(knn_num_train, -1)\n","knn_hog_data_dict['y_train'] = y_train[:knn_num_train]\n","knn_hog_data_dict['X_val'] = np.array(X_train_hog[knn_num_train:knn_num_train+knn_num_val]).reshape(knn_num_val, -1)\n","knn_hog_data_dict['y_val'] = y_train[knn_num_train:knn_num_train+knn_num_val]\n","knn_hog_data_dict['X_test'] = np.array(X_test_hog[:knn_num_test]).reshape(knn_num_test, -1)\n","knn_hog_data_dict['y_test'] = y_test[:knn_num_test]\n","\n","print('Train data shape: ', knn_hog_data_dict['X_train'].shape)\n","print('Train labels shape: ', knn_hog_data_dict['y_train'].shape)\n","print('Validation data shape: ', knn_hog_data_dict['X_val'].shape)\n","print('Validation labels shape: ', knn_hog_data_dict['y_val'].shape)\n","print('Test data shape: ', knn_hog_data_dict['X_test'].shape)\n","print('Test labels shape: ', knn_hog_data_dict['y_test'].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywP8WhXCv270"},"outputs":[],"source":["classifier = KNearestNeighbor()\n","classifier.train(knn_hog_data_dict['X_train'], knn_hog_data_dict['y_train'])\n","dists = classifier.compute_distances_no_loops(knn_hog_data_dict['X_test'])\n","y_test_pred, k_labels  = classifier.predict_labels(dists, k=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmpaoF1QyImO"},"outputs":[],"source":["# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_hog_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))"]},{"cell_type":"markdown","metadata":{"id":"92-AabhbRcet"},"source":["You can also visualize the K nearest images for some randomly selected examples from the test set using the k_idxs list you returned in predict_labels trained with HOG descriptors."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXbIp8IDhJBS"},"outputs":[],"source":["def visualize_knn_sift(num_examples, K):\n","  idxs = np.random.choice(knn_num_test, num_examples,replace=False)\n","  vis_im = knn_data_dict['X_test'][idxs]\n","  vis_labels = np.stack(k_labels, axis=0)[idxs].astype('uint8')\n","\n","  num_images = num_examples*K + num_examples\n","  plt.figure(figsize=(14,8))\n","  for i in range(num_images):\n","    plt.subplot(num_examples,K+1,i+1)\n","    if (i%(K+1) == 0):\n","      plt.imshow(vis_im[int(i/(K+1))].reshape(img_size,img_size,3).astype('uint8'), interpolation='nearest')\n","      plt.axis('off')\n","      if(i==0):\n","        plt.title('Input Image')\n","    else:\n","      plt.imshow(knn_data_dict['X_train'][vis_labels[int(i/(K+1)), i - (K+1)*int(i/(K+1)) - 1]].reshape(img_size,img_size,3).astype('uint8'))\n","      plt.axis('off')\n","\n","\n","\n","# Here the leftmost column is the input image from the test set and rest of the\n","# K columns are the K nearest neighbors from the training set\n","num_examples = 5\n","K = 3\n","visualize_knn_sift(num_examples, K)"]},{"cell_type":"markdown","metadata":{"id":"_WdFIJlB47-O"},"source":["### (e) (EXTRA) scikit-image’s HOG implementation\n","We have provided the Skimage implementation that computes full HOG features. These features should obtain significantly higher accuracy. You can read about it further [here](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n-_iHAAM2oXH"},"outputs":[],"source":["X_train_skimage_hog = []\n","for image_index in range(X_train.shape[0]):\n","  histogram = hog(X_train[image_index], pixels_per_cell=(4, 4), cells_per_block=(4, 4), channel_axis=-1)\n","  X_train_skimage_hog.append(histogram)\n","\n","X_test_skimage_hog = []\n","for image_index in range(X_test.shape[0]):\n","  histogram = hog(X_test[image_index], pixels_per_cell=(4, 4), cells_per_block=(4, 4), channel_axis=-1)\n","  X_test_skimage_hog.append(histogram)\n","\n","knn_skimage_hog_data_dict = {}\n","\n","knn_skimage_hog_data_dict['X_train'] = np.array(X_train_skimage_hog[:knn_num_train]).reshape(knn_num_train, -1)\n","knn_skimage_hog_data_dict['y_train'] = y_train[:knn_num_train]\n","knn_skimage_hog_data_dict['X_val'] = np.array(X_train_skimage_hog[knn_num_train:knn_num_train+knn_num_val]).reshape(knn_num_val, -1)\n","knn_skimage_hog_data_dict['y_val'] = y_train[knn_num_train:knn_num_train+knn_num_val]\n","knn_skimage_hog_data_dict['X_test'] = np.array(X_test_skimage_hog[:knn_num_test]).reshape(knn_num_test, -1)\n","knn_skimage_hog_data_dict['y_test'] = y_test[:knn_num_test]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GsszYwlI4CDt"},"outputs":[],"source":["classifier = KNearestNeighbor()\n","classifier.train(knn_skimage_hog_data_dict['X_train'], knn_skimage_hog_data_dict['y_train'])\n","\n","dists = classifier.compute_distances_no_loops(knn_skimage_hog_data_dict['X_test'])\n","y_test_pred, k_labels  = classifier.predict_labels(dists, k=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0QHkMPGD0Ddd"},"outputs":[],"source":["# Compute and print the fraction of correctly predicted examples\n","num_correct = np.sum(y_test_pred == knn_skimage_hog_data_dict['y_test'])\n","accuracy = float(num_correct) / knn_num_test\n","print('Got %d / %d correct => accuracy: %f' % (num_correct, knn_num_test, accuracy))"]},{"cell_type":"markdown","metadata":{"id":"XExdmeo9YIHy"},"source":["## **Problem 3.2**\n","Linear classifier with Softmax Loss"]},{"cell_type":"markdown","metadata":{"id":"IXzk9EAFOLct"},"source":["### Preprocess images\n","\n","We need 1-D vectors to use  with Linear classifer. Hence in this function below we flatten the ``` [N, 32, 32, 3] ``` images into one dimesional arrays of shape ``` [N, 3072] ``` and we append a row of ones for each image, to accomodate for the bias when using the bias trick. This makes the shape of the input images ``` [N, 3073] ```. We also normalize the data by subtracting the mean image from the train and test data.   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHMthnPPViFB"},"outputs":[],"source":["train_dataset = ImageDataset(train_image_paths, img_shape=img_size, is_tensor=False)\n","test_dataset = ImageDataset(test_image_paths, img_shape=img_size, is_tensor=False)\n","\n","train_batch_size = train_dataset.__len__()\n","test_batch_size = test_dataset.__len__()\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset, batch_size=test_batch_size, shuffle=True\n",")\n","\n","iterator = iter(train_loader)\n","# X_train, y_train = iter(train_loader).next()\n","for batch_train in train_loader:\n","    X_train, y_train = batch_train\n","\n","iterator = iter(test_loader)\n","# X_test, y_test = iter(test_loader).next()\n","for batch_test in test_loader:\n","    X_test, y_test = batch_test\n","\n","X_train = X_train.numpy()\n","y_train = y_train.numpy()\n","X_test = X_test.numpy()\n","y_test = y_test.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaA2HJ8Wol4o"},"outputs":[],"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhFUm5VyNkCS"},"outputs":[],"source":["if DEBUG:\n","  num_training=1900\n","  num_validation=100\n","  num_test=3925\n","else:\n","  num_training=9000\n","  num_validation=538\n","  num_test=3856\n","\n","# Flatten the images\n","X_train = X_train.reshape(X_train.shape[0], -1)\n","X_test = X_test.reshape(X_test.shape[0], -1)\n","\n","# Normalize the data: subtract the mean image from train and test data\n","mean_image = np.mean(X_train, axis=0, keepdims=True)\n","X_train -= mean_image\n","X_test -= mean_image\n","\n","# Append the bias dimension of ones (i.e. bias trick) so that our classifier\n","# only has to worry about optimizing a single weight matrix W.\n","ones_train = np.ones((X_train.shape[0],1))\n","X_train = np.concatenate((X_train, ones_train), axis=1)\n","ones_test = np.ones((X_test.shape[0],1))\n","X_test = np.concatenate((X_test, ones_test), axis=1)\n","\n","# Store them in a dictionary.\n","data_dict={}\n","data_dict['X_train'] = X_train[0:num_training]\n","data_dict['y_train'] = y_train[0:num_training]\n","data_dict['X_val'] = X_train[num_training:num_training+num_validation]\n","data_dict['y_val'] = y_train[num_training:num_training+num_validation]\n","data_dict['X_test'] = X_test[0:num_test]\n","data_dict['y_test'] = y_test[0:num_test]\n","\n","print('Train data shape: ', data_dict['X_train'].shape)\n","print('Train labels shape: ', data_dict['y_train'].shape)\n","print('Validation data shape: ', data_dict['X_val'].shape)\n","print('Validation labels shape: ', data_dict['y_val'].shape)\n","print('Test data shape: ', data_dict['X_test'].shape)\n","print('Test labels shape: ', data_dict['y_test'].shape)"]},{"cell_type":"markdown","metadata":{"id":"gmFVQtMnYYE1"},"source":["### (a) Softmax_loss_naive function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHp14GpdIzK8"},"outputs":[],"source":["def softmax_loss_naive(W, X, y):\n","  \"\"\"\n","  Softmax loss function, naive implementation (with loops)\n","  Inputs have dimension D, there are C classes, and we operate on minibatches\n","  of N examples.\n","  Inputs:\n","  - W: A numpy array of shape (D, C) containing weights.\n","  - X: A numpy array of shape (N, D) containing a minibatch of data.\n","  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n","    that X[i] has label c, where 0 <= c < C.\n","  Returns a tuple of:\n","  - loss: loss as single float\n","  - dW: gradient with respect to weights W averaged across the whole batch;\n","     an array of same shape as W\n","  \"\"\"\n","  # Initialize the loss and gradient to zero.\n","  loss = 0.0\n","  dW = np.zeros_like(W)\n","\n","  num_classes = W.shape[1]\n","  num_train = X.shape[0]\n","\n","  # ===== your code here! =====\n","\n","  # TODO:\n","  # Loop over each example in the batch\n","  # Calculate the scores\n","  # Compute the softmax loss\n","  # Compute gradient dW using explicit loop\n","  # Average loss and gradient across the whole batch\n","  # Note: When calculating dW, subtract the maximum score from each scores to\n","  # avoid infinity (See note in the PSet).\n","\n","\n","  # ==== end of code ====\n","\n","  return loss, dW"]},{"cell_type":"markdown","metadata":{"id":"zvUhL1Imnt5w"},"source":["As a sanity check to see whether we have implemented the loss correctly, run the softmax classifier with a small random weight matrix and no regularization. **If your implementation is correct you should see loss near  -ln(1/10) = 2.3**\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIVNDmmfmUiZ"},"outputs":[],"source":["# Generate a random weight matrix of small numbers and use it to compute the loss\n","random.seed(0)\n","np.random.seed(0)\n","W = np.random.randn((img_size*img_size*3)+1, 10) * 0.00001\n","\n","# For debugging purpose we can calculate the loss with very low W and no regularization\n","# The result should be near log(10) (log(#number_class))\n","\n","loss, grad = softmax_loss_naive(W, data_dict['X_val'], data_dict['y_val'])\n","print('loss: %f' % (loss))\n","print('sanity check: %f' % (np.log(10.0)))"]},{"cell_type":"markdown","metadata":{"id":"C3V7QK_uqfNU"},"source":["To check that you have implemented the gradient correctly, you can numerically estimate the gradient of the loss function and compare the numeric estimate to the gradient that you computed. We have provided code that does this for you    \n","\n"," **(The relative errors should be less than 1e-6)**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mWGXrRkm1FP"},"outputs":[],"source":["# Compute the loss and its gradient at W.\n","loss, grad = softmax_loss_naive(W, data_dict['X_val'], data_dict['y_val'])\n","\n","# Numerically compute the gradient along several randomly chosen dimensions, and\n","# compare them with your analytically computed gradient. The numbers should match\n","# almost exactly along all dimensions.\n","\n","f = lambda w: softmax_loss_naive(w, data_dict['X_val'], data_dict['y_val'])[0]\n","grad_numerical = grad_check_sparse(f, W, grad)"]},{"cell_type":"markdown","metadata":{"id":"IXDMjV_Ry-GP"},"source":["Next, we implement a vecotrized version of the softmax loss for you, for faster execution, as we quantify the speedup in the below cells. If you want to get a flavor of writing optimized (vectorized) code in the future for Deep Learning systems as well as future homeworks, it might be helpful to go through this function **AFTER** finishing the required parts of the Problem Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CEnT8AVlg5eN"},"outputs":[],"source":["def softmax_loss_vectorized(W, X, y):\n","  \"\"\"\n","  Softmax loss function, vectorized version.\n","  Inputs and outputs are the same as softmax_loss_naive.\n","  \"\"\"\n","\n","  dW = np.zeros(W.shape) # initialize the gradient as zero\n","  loss = 0.0             # initialize the loss as zero\n","\n","  num_train = X.shape[0]\n","  scores = X.dot(W)\n","  scores -= np.max(scores, axis =1, keepdims = True)\n","  exp_scores = np.exp(scores)\n","  scores_exp_sum = np.sum(exp_scores, axis=1, keepdims=True)\n","  norm_scores = exp_scores/(scores_exp_sum + 1e-12)\n","  loss = np.sum(-np.log(norm_scores[range(num_train),y]))\n","\n","  norm_scores[np.arange(num_train),y] -= 1\n","  dW = np.matmul(X.T, norm_scores)\n","\n","  loss/=num_train\n","  dW/=num_train\n","\n","  return loss,dW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIEmKrCHK2zc"},"outputs":[],"source":["# Now that we have a naive implementation of the softmax loss function and its gradient,\n","# we have provided a vectorized version in softmax_loss_vectorized.\n","# The two versions should compute the same results, but the vectorized version should be\n","# much faster.\n","\n","tic = time.time()\n","loss_naive, grad_naive = softmax_loss_naive(W, data_dict['X_val'], data_dict['y_val'])\n","toc = time.time()\n","ms_naive = 1000.0 * (toc - tic)\n","print('naive loss: %e computed in %fs' % (loss_naive, ms_naive))\n","\n","tic = time.time()\n","loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, data_dict['X_val'], data_dict['y_val'])\n","toc = time.time()\n","ms_vec = 1000.0 * (toc - tic)\n","print('vectorized loss: %e computed in %fs' % (loss_vectorized, ms_vec))\n","\n","# As we did for the SVM, we use the Frobenius norm to compare the two versions\n","# of the gradient.\n","grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n","print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n","print('Gradient difference: %f' % grad_difference)\n","print('Speedup: %f' %(ms_naive/ms_vec))"]},{"cell_type":"markdown","metadata":{"id":"EtBXeuMVY2DK"},"source":["### (b) Define Linear Classifier class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0VO4DXFQ0A1"},"outputs":[],"source":["class LinearClassifier(object):\n","\n","  def __init__(self):\n","    self.W = None\n","\n","  def train(self, X, y,  X_val, y_val, learning_rate=1e-3, num_iters=100,\n","            batch_size=200, verbose=False):\n","    \"\"\"\n","    Train this linear classifier using stochastic gradient descent.\n","    Inputs:\n","    - X: A numpy array of shape (N, D) containing training data; there are N\n","      training samples each of dimension D.\n","    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n","      means that X[i] has label 0 <= c < C for C classes.\n","    - learning_rate: (float) learning rate for optimization.\n","    - num_iters: (integer) number of steps to take when optimizing\n","    - batch_size: (integer) number of training examples to use at each step.\n","    - verbose: (boolean) If true, print progress during optimization.\n","    Outputs:\n","    A list containing the value of the loss function at each training iteration.\n","    \"\"\"\n","\n","    num_train, dim = X.shape\n","    num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n","    if self.W is None:\n","      # lazily initialize W\n","      self.W = 0.000001 * np.random.randn(dim, num_classes)\n","\n","    # Run stochastic gradient descent to optimize W\n","    loss_history = []\n","    for it in range(num_iters):\n","      X_batch = None\n","      y_batch = None\n","\n","      # ==== your code here ! ====\n","\n","      # TODO:\n","      # Sample batch_size elements from the training data and their\n","      # corresponding labels to use them as arguments for the loss\n","      # function. Store the data in X_batch and their corresponding labels\n","      # in y_batch.\n","\n","      # Hint: Use np.random.choice to generate indices. Sampling with\n","      # replacement is faster than sampling without replacement.\n","\n","\n","      # ===== end of code =====\n","\n","      # evaluate loss and gradient\n","      loss, grad = self.loss(X_batch, y_batch)\n","      loss_history.append(loss)\n","\n","      # perform parameter update\n","\n","      # ==== your code here ! ====\n","\n","      # TODO:\n","      # Update the weights using the gradient and the learning rate.\n","\n","\n","      # ===== end of code =====\n","\n","      if verbose and it % 100 == 0:\n","        print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n","\n","      y_val_pred = self.predict(X_val)\n","      val_accuracy = np.mean(y_val == y_val_pred)\n","\n","    return loss_history\n","\n","  def predict(self, X):\n","    \"\"\"\n","    Use the trained weights of this linear classifier to predict labels for\n","    data points.\n","    Inputs:\n","    - X: A numpy array of shape (N, D) containing training data; there are N\n","      training samples each of dimension D.\n","    Returns:\n","    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n","      array of length N, and each element is an integer giving the predicted\n","      class.\n","    \"\"\"\n","    y_pred = np.zeros(X.shape[0])\n","    # ==== your code here ! ====\n","\n","    # TODO:\n","    # Calculate the scores and store the predicted labels in y_pred.\n","\n","\n","    # ===== end of code =====\n","    return y_pred\n","\n","  def loss(self, X_batch, y_batch):\n","    \"\"\"\n","    Compute the loss function and its derivative.\n","    Subclasses will override this.\n","    Inputs:\n","    - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n","      data points; each point has dimension D.\n","    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n","    - reg: (float) regularization strength.\n","    Returns: A tuple containing:\n","    - loss as a single float\n","    - gradient with respect to self.W; an array of the same shape as W\n","    \"\"\"\n","    pass\n","\n","class LinearSoftmax(LinearClassifier):\n","  \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n","\n","  def loss(self, X_batch, y_batch):\n","    return softmax_loss_vectorized(self.W, X_batch, y_batch)"]},{"cell_type":"markdown","metadata":{"id":"RGij3_HeY_rr"},"source":["### (d) Train and test the classifier\n","Run the linear classifier and observe the train, validation and test accuracies and see the visualization of the weights. The loss should start around 2.300 and reduce over iterations to final value between 1.800 and 1.600."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0Pqa524sSTP"},"outputs":[],"source":["softmax = LinearSoftmax()\n","tic = time.time()\n","loss_hist = softmax.train(data_dict['X_train'], data_dict['y_train'], learning_rate=1e-7,\n","                      num_iters=1500, verbose=True, X_val=data_dict['X_val'], y_val=data_dict['y_val'])\n","toc = time.time()\n","print('That took %fs' % (toc - tic))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Al0U0pN7tnQG"},"outputs":[],"source":["# A useful debugging strategy is to plot the loss as a function of\n","# iteration number:\n","plt.plot(loss_hist)\n","plt.xlabel('Iteration number')\n","plt.ylabel('Loss value')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sY1Y1SYZvBcF"},"outputs":[],"source":["# Write the LinearSoftmax.predict function and evaluate the performance on both the\n","# training and validation set\n","y_train_pred = softmax.predict(data_dict['X_train'])\n","print('training accuracy: %f' % (np.mean(data_dict['y_train'] == y_train_pred), ))\n","y_val_pred = softmax.predict(data_dict['X_val'])\n","print('validation accuracy: %f' % (np.mean(data_dict['y_val'] == y_val_pred), ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIs0qkBQvQKb"},"outputs":[],"source":["# Evaluate the best softmax on test set\n","y_test_pred = softmax.predict(data_dict['X_test'])\n","test_accuracy = np.mean(data_dict['y_test'] == y_test_pred)\n","print('Linear Softmax on raw pixels final test set accuracy: %f' % test_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"BppqEvlfFMOt"},"source":[" Visualize the learned weights for each class. You might be able to spot a few defining features of each class in these weights."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac8Gxty86VXZ"},"outputs":[],"source":["w = softmax.W[:-1,:] # strip out the bias\n","w = w.reshape(img_size, img_size, 3, 10)\n","w_min, w_max = np.min(w), np.max(w)\n","\n","figure, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 8))\n","for i in range(10):\n","    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n","    ax.ravel()[i].imshow(wimg.astype('uint8'))\n","    ax.ravel()[i].set_axis_off()\n","    ax.ravel()[i].set_title(idx_to_class[i])\n","plt.tight_layout(pad=1)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YvH4VkqRFP2f"},"source":["## Visualize the mean image for each class"]},{"cell_type":"markdown","metadata":{"id":"UH-O7WcGqXDm"},"source":["Here we visualize an average image for each class by adding a few images and avergaing the pixel values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiYD5Kg8FI7N"},"outputs":[],"source":["samples_per_class = 20\n","train_dataset = ImageDataset(train_image_paths, img_shape=img_size, is_tensor=False)\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=samples_per_class*10, shuffle=True\n",")\n","\n","iterator = iter(train_loader)\n","# X_train, y_train = iter(train_loader).next()\n","for batch_train in train_loader:\n","    X_train, y_train = batch_train\n","\n","\n","X_train = X_train.numpy()\n","y_train = y_train.numpy()\n","\n","figure, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 8))\n","for i in range(10):\n","    idxs = np.flatnonzero(y_train == i)\n","    mean_img = np.mean(X_train[idxs], axis = 0)\n","    ax.ravel()[i].imshow(mean_img.reshape(img_size,img_size,3).astype('uint8'))\n","    ax.ravel()[i].set_axis_off()\n","    ax.ravel()[i].set_title(idx_to_class[i])\n","plt.tight_layout(pad=1)\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"Vi1piE3vLhVG"},"source":["# Convert Notebook to PDF"]},{"cell_type":"code","source":["# Please provide the full path of the notebook file below\n","# Important: make sure that your file name does not contain spaces!\n","import os\n","notebookpath = '' # Ex: notebookpath = '/content/drive/My Drive/Colab Notebooks/EECS 442 Fall 2023 - PS3.ipynb'\n","drive_mount_point = '/content/drive/'\n","from google.colab import drive\n","drive.mount(drive_mount_point)\n","file_name = notebookpath.split('/')[-1]\n","get_ipython().system(\"apt update && apt install texlive-xetex texlive-fonts-recommended texlive-generic-recommended\")\n","get_ipython().system(\"pip install pypandoc\")\n","get_ipython().system(\"apt-get install texlive texlive-xetex texlive-latex-extra pandoc\")\n","get_ipython().system(\"jupyter nbconvert --to PDF {}\".format(notebookpath.replace(' ', '\\\\ ')))\n","from google.colab import files\n","files.download(notebookpath.split('.')[0]+'.pdf')"],"metadata":{"id":"VUUDzMffBYXc"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1YhQluWxZ_hGZL9AYF-Qc-Vsd8ZM-iBua","timestamp":1703323545488},{"file_id":"16CqvA-XrTZkTy9TmAwJkIlNutfknHgVH","timestamp":1694743064778}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}